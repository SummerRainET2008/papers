\section{Related work}
We supplement some work that is very different from classic classification models.

One  line  of  work  is  based  on  label-word  joint  embedding,  such  as LEAM
\cite{wang2018joint}, MTLE \cite{zhang2017multi} and EXAM \cite{du2019explicit}.
It  poses  extral  requirements  on label information. However in our case, many
class  labels  are  close  to  each  other,  and not well-defined. Though we can
present the class label with one of user's utterances from that class, the label
will  become  not  only prolix but also biased.

Another   line   of   interesting   work  is  the  joint  training  of  sentence
classification     and     NER,     such    as    
\cite{kruengkrai2020improving,zhang2020graph,hakkani2016multi,liu2016attention,goo2018slot}.  
For  example,  If  both  the  city and date information are
recognized,  then  they  are good indicators that this query might be booking an
ticket. Considering a joint model, our framework is supportive of NER
training using the same method as mentioned in \cite{chen2019bert}. 
However in our case, the four public datasets and one private dataset we are using
do not have any NER information. Thus, in this work, we exclusively compare the classification
performance. 

